{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Peptide Samples by Biophysical Properties\n",
    "\n",
    "### This notebook describes additional ranking of the sampled sequences based on their biophysical properties.\n",
    "\n",
    "### Enhancing Sequence Selection\n",
    "\n",
    "- This ranking in useful in streamlining the selection of sequences. For instance, it can prioritise specific \n",
    "samples for experimental validation, ensuring that those with the most desirable biophysical characteristics are tested first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "from peptide_models.aminoacids import AMINOACIDS\n",
    "from peptide_models.peptide import Peptide\n",
    "from peptide_models.utils_data import fasta2df, get_peptides, pep2fasta, peptides2df, save_frame\n",
    "from peptide_models.utils_models import get_predictions\n",
    "from peptide_models.optimize_main import select_sequences\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_properties(peptides_list: List[Peptide]) -> Dict:\n",
    "    \"\"\"\n",
    "    Computes average biophysical properties \n",
    "    :param peptides_list: list of peptide instances\n",
    "    :return: dictionary with properties\n",
    "    \"\"\"\n",
    "    names_properties = ['M',\n",
    "                        'pI',\n",
    "                        'A',\n",
    "                        'G',\n",
    "                        'II',\n",
    "                        'MW']\n",
    "    MW, pI, A, G, II, M = [], [], [], [], [], []\n",
    "    for pep in peptides_list:\n",
    "        MW.append(pep.molecular_weight)\n",
    "        pI.append(pep.pi)\n",
    "        G.append(pep.gravy)\n",
    "        M.append(pep.m_ext_coefficient)\n",
    "        II.append(pep.instability_index)\n",
    "        A.append(pep.aromaticity)\n",
    "\n",
    "    mean_MW, std_MW = np.asarray(MW).mean(), np.asarray(MW).std()\n",
    "    mean_pI, std_pI = np.asarray(pI).mean(), np.asarray(pI).std()\n",
    "    mean_A, std_A = np.asarray(A).mean(), np.asarray(A).std()\n",
    "    mean_G, std_G = np.asarray(G).mean(), np.asarray(G).std()\n",
    "    mean_II, std_II = np.asarray(II).mean(), np.asarray(II).std()\n",
    "    mean_M, std_M = np.asarray(M).mean(), np.asarray(M).std()\n",
    "    properties = dict(zip(names_properties, [(mean_MW, std_MW),\n",
    "                                             (mean_pI, std_pI),\n",
    "                                             (mean_A, std_A),\n",
    "                                             (mean_G, std_G),\n",
    "                                             (mean_II, std_II),\n",
    "                                             (mean_M, std_M)]))\n",
    "    return properties\n",
    "\n",
    "def rank_peptides(data_frame: pd.DataFrame, \n",
    "                  properties_dict: Dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sorts peptides based on the number of features \n",
    "    whose values are within one standard deviation \n",
    "    of the mean calculated for the\n",
    "    corresponding group of training set sequences.\n",
    "    :param data_frame: \n",
    "    :param properties_dict: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    properties = ['M', 'pI', 'A', 'G', 'II', 'MW']\n",
    "    for prop in properties:\n",
    "        m, std = properties_dict[prop][0], properties_dict[prop][1]\n",
    "        data_frame[prop] = [True if m - std <= x <= m + std else False for x in\n",
    "                            data_frame[prop]]\n",
    "    data_frame['rank'] = data_frame[[col for col in properties]].sum(axis=1)\n",
    "    data_frame.sort_values(by=['rank'], inplace=True, ascending=False)\n",
    "    data_frame.index = range(1, len(data_frame)+1)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select from the training set relevant subsets of peptides based on their potencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = Path('../data/training_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(str(training_data_path),\n",
    "                        index_col=0,\n",
    "                        header=0,\n",
    "                        skiprows=0,\n",
    "                        sheet_name='dataset')\n",
    "msa = pd.read_excel(str(training_data_path),\n",
    "                    index_col=0,\n",
    "                    header=0,\n",
    "                    skiprows=0,\n",
    "                    sheet_name='alignment')\n",
    "\n",
    "training_peptides = []\n",
    "for idx in range(len(dataset)):\n",
    "    pep_record = dataset.iloc[idx]\n",
    "    peptide = Peptide(alias=pep_record.alias,\n",
    "                      ec_50A=pep_record.EC50_LOG_T1,\n",
    "                      ec_50B=pep_record.EC50_LOG_T2,\n",
    "                      name=idx,\n",
    "                      sequence=msa.iloc[idx].sequence,\n",
    "                      c_term=True)\n",
    "    training_peptides.append(peptide)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peptde selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCGR_selective, GLP1R_selective, bothR_high_potency = select_sequences(training_peptides, low_th=-11, high_th=-11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess the mean biophysical properties of sequences in the training set, categorised by each activity group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_dict_GCGR_selective = get_average_properties(GCGR_selective)\n",
    "properties_dict_GLP1R_selective = get_average_properties(GLP1R_selective)\n",
    "properties_dict_bothR_high_potency = get_average_properties(bothR_high_potency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_dict_bothR_high_potency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort samples based on the alignment of biophysical properties "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) First generation of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_path = Path('../results/ligand_design/samples/predictions/gen_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_path in sorted(samples_path.iterdir()):\n",
    "        print('file:', str(f_path))\n",
    "        name_df = str(f_path).split('/')[-1].split('.xlsx')[0]\n",
    "        if name_df == 'high_potency_at_both':\n",
    "            data_high_potency_at_both = pd.read_excel(str(f_path),\n",
    "                                        index_col=0,\n",
    "                                        header=0,\n",
    "                                        skiprows=0)\n",
    "        elif name_df == 'selective_towards_GCGR':\n",
    "            data_selective_towards_GCGR = pd.read_excel(str(f_path),\n",
    "                                        index_col=0,\n",
    "                                        header=0,\n",
    "                                        skiprows=0)\n",
    "        else:\n",
    "            data_selective_towards_GLP1R = pd.read_excel(str(f_path),\n",
    "                                        index_col=0,\n",
    "                                        header=0,\n",
    "                                        skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high_potency_at_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high_potency_at_both_ranked = rank_peptides(data_frame = data_high_potency_at_both, \n",
    "                                                 properties_dict = properties_dict_bothR_high_potency)\n",
    "data_selective_towards_GLP1R_ranked = rank_peptides(data_frame = data_selective_towards_GLP1R,\n",
    "                                                    properties_dict = properties_dict_GLP1R_selective)\n",
    "data_selective_towards_GCGR_ranked = rank_peptides(data_frame = data_selective_towards_GCGR, \n",
    "                                                   properties_dict = properties_dict_GCGR_selective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save ranked sequenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = samples_path\n",
    "name_file = 'ranked_sequences'\n",
    "\n",
    "with pd.ExcelWriter(str(Path(output_path, name_file).with_suffix('.xlsx'))) as writer:\n",
    "    data_high_potency_at_both_ranked.to_excel(writer, sheet_name='high_potency_at_both',\n",
    "                index=True, float_format='%.4f')\n",
    "    data_selective_towards_GLP1R_ranked.to_excel(writer, sheet_name='selective_towards_GLP1R',\n",
    "                index=True, float_format='%.4f')\n",
    "    data_selective_towards_GCGR_ranked.to_excel(writer, sheet_name='selective_towards_GCGR',\n",
    "                index=True, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Third generation of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_path = Path('../results/ligand_design/samples/predictions/gen_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_path in sorted(samples_path.iterdir()):\n",
    "        print('file:', str(f_path))\n",
    "        name_df = str(f_path).split('/')[-1].split('.xlsx')[0]\n",
    "        if name_df == 'high_potency_at_both':\n",
    "            data_high_potency_at_both = pd.read_excel(str(f_path),\n",
    "                                        index_col=0,\n",
    "                                        header=0,\n",
    "                                        skiprows=0)\n",
    "        elif name_df == 'selective_towards_GCGR':\n",
    "            data_selective_towards_GCGR = pd.read_excel(str(f_path),\n",
    "                                        index_col=0,\n",
    "                                        header=0,\n",
    "                                        skiprows=0)\n",
    "        else:\n",
    "            data_selective_towards_GLP1R = pd.read_excel(str(f_path),\n",
    "                                        index_col=0,\n",
    "                                        header=0,\n",
    "                                        skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high_potency_at_both_ranked = rank_peptides(data_frame = data_high_potency_at_both, \n",
    "                                                 properties_dict = properties_dict_bothR_high_potency)\n",
    "data_selective_towards_GLP1R_ranked = rank_peptides(data_frame = data_selective_towards_GLP1R, \n",
    "                                                    properties_dict = properties_dict_GLP1R_selective)\n",
    "data_selective_towards_GCGR_ranked = rank_peptides(data_frame = data_selective_towards_GCGR, \n",
    "                                                   properties_dict = properties_dict_GCGR_selective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high_potency_at_both_ranked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save ranked sequenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = samples_path\n",
    "\n",
    "name_file = 'ranked_sequences'\n",
    "\n",
    "with pd.ExcelWriter(str(Path(output_path, name_file).with_suffix('.xlsx'))) as writer:\n",
    "    data_high_potency_at_both_ranked.to_excel(writer, sheet_name='high_potency_at_both',\n",
    "                index=True, float_format='%.4f')\n",
    "    data_selective_towards_GLP1R_ranked.to_excel(writer, sheet_name='selective_towards_GLP1R',\n",
    "                index=True, float_format='%.4f')\n",
    "    data_selective_towards_GCGR_ranked.to_excel(writer, sheet_name='selective_towards_GCGR',\n",
    "                index=True, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PeptideModels] *",
   "language": "python",
   "name": "conda-env-PeptideModels-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
